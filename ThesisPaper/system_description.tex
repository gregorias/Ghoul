\chapter{Ghoul system description}

In this chapter I present Ghoul's design. Section \ref{sec:ghoul_goals}
describes the problem that Ghoul solves and its assumptions. Section
\ref{sec:ghoul_overview} provides an overview of the protocols used in Ghoul.
Sections \ref{sec:ghoul_data} and \ref{sec:ghoul_protocols} describe in detail
Ghoul's mechanisms - its data structures and protocols. The final section
\ref{sec:ghoul_summary} describes Ghoul's strengths and weaknesses..

\section{Goals}
\label{sec:ghoul_goals}
I decided to build Ghoul to fill a niche of secure open-source DHT network
implementation. In my experience it is difficult to find a satisfactory
open-source implementation of Kademlia DHT. By satisfactory I mean one that
satisfies all of the following criterias:

\begin{description}
  \item{\textbf{Single responsibility}} Implementation of Kademlia should do
    only one thing: operate according to the Kademlia protocol.
  \item{\textbf{Extensibility}} Extension of the network protocol with a
    NAT traversal mechanism should not require modification of a large portion
    of the library's network communication stack.
  \item{\textbf{Documentation}} An open-source project should have maintained
    documentation to help others contribute or use it.
  \item{\textbf{Robustness}} Implementation should not fail after it is used
    for 1 hour on a small network consisting of a hundred nodes.
\end{description}

I couldn't find an implementation that satisfies all of the above in Java and
none that would satisfiably claim to be secure in any language. Some examples
that I have considered are:
openkad\footnote{\texttt{https://code.google.com/p/openkad/}}, which does not
implement DHT storage operations, TomP2P\footnote{\texttt{http://tomp2p.net/}},
which never worked without a failure, even after a few bug patches, and
JoshuaKissoon/Kademlia
\footnote{\texttt{https://github.com/JoshuaKissoon/Kademlia}}, which is not
extensible.

Solutions used in KAD network and designed for Mainline DHT use IP addresses to
prevent Sybil attack and arbitrary ID choice. This approach works against
unsophisticated attacker, but has problems stemming from the fact that IP was
not designed for that use case. IP spoofing, IPv6 privacy extensions and lack of
anonymity are serious concerns that either neutralize such solution or introduce
a serious flaw. I feel that lack of adoption of security measures that are
present in the research literature stems from the stereotype that such measures
are either hard to implement, slow, hard to satisfy their dependencies, or
needlessly complicate use of the application. With Ghoul I show that it is
possible to design and build a DHT that satisfies following constraints:

\begin{description}
  \item{\textbf{Security}} The DHT should be resistant to Sybil and
    eclipse attacks.
  \item{\textbf{Performance}} The DHT should be as performant as the original
    protocol where possible, especially in common use cases of finding a node,
    storing and getting. In other cases the time of operation should be
    practical, meaning that time or message complexity should not be greater
    than $O(\log n)$ for network of size $n$.
  \item{\textbf{Simplicity}} The DHT should be simple to use. User should not be
    forced to perform an extensive set up, or prepare a large configuration file
    to just start the DHT.  The entire scheme should be simple to describe. User
    or developer should be able to understand how the protection schemes work
    and be able to reason how it would behave in his application.
  \item{\textbf{Extensibility}} Application developers should be able to extend
    the system with their own security mechanism easily.
  \item{\textbf{Anonymity}} The security mechanism should not compromise user
    anonymity.
\end{description}

I assume standard threats and network conditions that is:

\begin{itemize}
  \item An attacker may introduce colluding nodes into the system, but has
    limited computing and communication power.
  \item There is only a point-to-point message passing primitive for network
    communication. Delivery time is not bounded and mail fail altogether.
  \item Nodes may exhibit byzantine failure.
\end{itemize}

\section{Overview}
\label{sec:ghoul_overview}
Ghoul is built on top of the Kademlia DHT protocol. Each node in the system is
an independent agent which acts as a Ghoul node and communicates with other
nodes using messages sent over a network.

There are two kinds of nodes in the system: a DHT node and a registration
authority. A DHT node is a Kademlia node extended with security measures.
It initiates and maintains its routing table and answers queries. Additionally,
each DHT node is responsible for maintaining the security of the entire network
by participating in P2P certificate revocation propagation, maintaining its
security certificate, and responding to security queries.

A small set of nodes, called registration nodes, is responsible for facilitating
nodeâ€™s join into the network by using distributed random key generation and
certificate issuance. Registration nodes are a distributed version of central
authority, with a twist that a few of them might be malicious. Their existence
is motivated by the fact that it is very hard to guarantee random key generation
and verification in a fully distributed setting. On the other, it is desirable
for the system to have at least administrative scalability. Application's owner
should be able to allow other parties to provide their registration nodes for
the protocol. Users should not worry whether registration nodes have
non-malicious intentions. The registration protocol works correctly as long as a
single node is honest.

\section{Data structures}
\label{sec:ghoul_data}

\subsection{Public key cryptography}
Ghoul uses public key cryptography for node authentication and certification.
Every DHT node and every registration node generates a public/private key pair
on its first entry. The private key is always kept private. The public key will
be propagated. Additionally, public keys of registration nodes are known by all
nodes.

To participate in the network a DHT node requires a \textbf{certificate}.
A certificate is a tuple consisting of:
(\texttt{NODE\_PUB\_KEY},~\texttt{NODE\_DHT\_KEY},~\texttt{EXPIRATION\_DATETIME})
signed with a registration node's private key such that it is known which node
signed it. Such a certificate is given by the registration node together with
\texttt{NODE\_DHT\_KEY}. The certificate serves as a proof that the node is
valid and its key was generated randomly by a set of registration nodes. If the
key is generated by a group of registration nodes then each of them provides a
separate certificate.

We say that a node is valid if it has at least $m$ non-expired, non-revoked
certificates generated by different registration nodes. The parameter $m$ should
be set to such a value that we are sure that there can be at most $m-1$
malicious registration nodes.

Every node maintains a store for valid certificates that it has received from
other nodes. This store may be limited in size. In such a case a node may remove
certificates of the last seen node or certificates close to expiration.
Additionally every node in the routing table must have a valid certificate in
the store, otherwise the node should be removed from the routing table. If a
certificate of a Kademlia's neighbor is close to expiration then a
\texttt{PING} should be sent to get an updated certificate.

\subsection{Messages}
Ghoul extends each DHT message with following fields:
\begin{description}
  \item{\texttt{certificateRequest}} Signifies that a response to this message
    should contain a list of certificates. This field is set when the recipient
    is considered to be a neighbor or potential neighbor and either its
    certificates are not present, not valid, or close to expiration.
  \item{\texttt{certificates}} A list of valid certificates provided by the
    registration authority.
  \item{\texttt{signature}} A message signature signed with the sender's private
    key.
\end{description}

Those fields are piggybacked on normal Kademlia messages. The size of
\texttt{certificateRequest} and \texttt{signature} is negligible.
\texttt{certificates} field may have large size, where each certificate has a
size of $\approx$ 1KB. Fortunately, the list of certificates is sent
sporadically.

Each one of those additional fields is optional. If the signature field is not
provided it means that the node is not interested in being part of the network
and instead just uses it to find information. That is considered normal
behavior. Such node is not added to its interlocutor's routing table as such a
node doesn't even have to provide its DHT key. Such signatureless queries
will only be responded with requested information.
Otherwise every node should always sign its messages.

The \texttt{certificateRequest} field is set if all of the following conditions
are met:

\begin{itemize}
  \item The recipient's certificate is not present in the sender's store or is
    close to expiration.
  \item The recipient is in the routing table or may be considered a candidate.
\end{itemize}

If the \texttt{certificateRequest} field is set then the recipient should attach
a list of ts certificates to its response. If no response would be normally
given then it should respond with a \text{PONG} message.

If a response to the message with the \texttt{certificateRequest} does not have
a valid list of certificates then it is discarded.

\section{Protocols}
\label{sec:ghoul_protocols}
\subsection{Challenge protocol}
In some neuralgical and vulnerable points in the protocol we may intent to limit
the number of requests a node can make using cryptographic challenges. This
limit achieves two goals: It significantly increases the cost of an attack which
relies on number of queries, such as a Sybil attack; it provides a throttle
mechanism to prevent a node overload.

Whenever the protocol requires the node sending a query or a request to provide
a proof-of-work for this request the challenge protocol is used
(Fig. \ref{fig:chal_prot}).

\begin{figure}
\begin{msc}{Challenge protocol}
\setlength{\instdist}{9cm}
\setlength{\envinstdist}{3cm}
\declinst{client}{C}{Client}
\declinst{server}{S}{Server}
\mess{Send a challenge request}{client}{server}
\nextlevel
\action*{
\begin{minipage}{4cm}\centering
Choose a random nonce\\
$r\in\{0,1\}^*$,\\ difficulty $p \in \N$,\\ $t := \text{current time}$.
\end{minipage}}{server}
\nextlevel[6]
\mess{Send challenge $m_2 := (t, r, p)_{s_{pr}}$}{server}{client}
\nextlevel[1]
\action*{
\begin{minipage}{4cm}\centering
  Find $s$ such that $H(r || s)$ has $p$ last bits equal to zero.
\end{minipage}}{client}
\nextlevel[5]
\mess{Send solution $m_3 := (m_2, s)$}{client}{server}
\nextlevel
\action*{
\begin{minipage}{4cm}\centering
Check the validity of the solution. Save $r$ into the active puzzles list
until the validity of the puzzle has ended.
\end{minipage}}{server}
\nextlevel[5]
\end{msc}
  \caption{Challenge protocol}
  \label{fig:chal_prot}
\end{figure}

The client initiates the protocol by sending a challenge request to the server. 
Upon receiving a request the server chooses the difficulty $p$ of the challenge
and a random nonce $r$. The server send the challenge $m_2$ consisting of $r$,
$p$, and current time on the server: $t$. $m_2$ is signed with server's private
key.  The client now has to find such a number $s$ that its concatenation with
$p$ ($p || s$) has a hash with $p$ last bits equal to zero. When such $s$ is
found then the client sends a message $m_3$ with the challenge $m_2$ and the
solution $s$. The server then checks the validity of the solution.

The validity check consists of: verifying signature of $m_2$, checking whether
nonce is not in the active puzzles list, checking time, verifying the hash of
the solution.

$m_3$ serves as a proof-of-work and may be accompanied by an additional request
to the server.

There is a variant to this scheme in which the server saves distributed nonces
and later checks that they exist in the distributed nonces list during
verification. Depending on the duration of the timeout and number of possible
queries per second this variant may provide a denial-of-service vulnerability.

\subsection{Robust distributed random key generation}

In Ghoul honesty of registrars is not assumed. In case of a single centralized
registrar such a node would greatly facilitate an eclipse attack by assigning to
colluding nodes keys close to a target. Therefore a verifiable distributed
scheme for key generation is needed.

Here I will present a distributed protocol which generates a random key that is
unbiased if at least one node is honest. More formally:

\begin{theorem*}
  Given a list $R = \langle r_1, \ldots, r_n \rangle$ of $n \geq 2$ nodes known
  to all nodes in $R$ the random key generation protocol generates an unbiased
  random key known to all participants if at least one node is honest and all
  nodes respond according to the protocol in a timely manner. Even in the case
  of a byzantine failure then all nodes that generate a key generate the same
  key that is unbiased if at least one non-failing node is honest.

  The chance that the malicious participant may manipulate the protocol so that
  this theorem does not hold is cryptographically negligible.
\end{theorem*}

The protocol that satisfies those properties is defined in
\ref{alg:key_gen_alg}.  It uses bit-commitment scheme which is defined as
follows:

\begin{defin*}[Bit-commitment]
  Bit-commitment is a cryptographic protocol that allows one to commit a value
  such that it is hidden and may be shared with others. Later the commiter may
  reveal the commited value to participants in such a way that they can check
  that it is indeed hidden in the earlier shared commitment. If the commiter
  tries to reveal a different value then this fact is detectable.

  Typical bit-commitment use is split into two phases:
  \begin{description}
    \item{\textbf{Hiding phase}} Commiter chooses a value and creates a
      commitment which hides the value. The commiter sends the commitment to
      interested parties.
    \item{\textbf{Reveal phase}} The value and the key used to create the
      commitment are revealed. Interested parties may check that they are
      consistent with earlier commitments.
  \end{description}

  Bit-commitment protocols may be either unconditionally binding, meaning even
  computationally unbounded commiter may not reveal a different value than the
  one commited, or unconditionally hiding, meaning no participant may find out
  the commited value. It can't be both.
\end{defin*}

The random number generation protocol consists of 3 phases:
\begin{enumerate}
  \item Commit and broadcast random number used to generate the key. This phase
    is used so that every node commits to its random number and can not change
    it later.
  \item Broadcast all received messages to others. This step ensures that every
    honest node has received the same set of messages and will generate the same
    key. If any node has sent inconsistent messages to honest nodes
    than this will be detected here.
  \item Broadcast key to unlock commitment.
\end{enumerate}

One may recognize that this protocol consist of the first two phases of a
3-phase byzantine failure protection protocol. Which is the reason why it has
its non-malleability properties.

\begin{algorithm}
  \begin{algorithmic}[1]
  \STATE $k_i \leftarrow $ random key
  \STATE $(h_i, s_i) \leftarrow $ bit commitment string and solution commiting
  $k_i$
  \FOR{$j := 1$ \TO $n$, $j \neq i$}
    \STATE Send $(h_i)_{i}$ to $r_j$
  \ENDFOR
  \STATE Wait $T$ seconds till all messages of the form $(h_j)_j$ are received
  from other nodes. If timeout happens then abort.
  \FOR{$j := 1$ \TO $n$, $j \neq i$}
    \STATE Send $\left( (h_1)_1, \ldots, (h_n)_{n}, k_i, s_i\right)_i$ to $r_j$
  \ENDFOR
  \STATE Wait $T$ seconds till all messages of the above form are received
  from other nodes. If timeout happens then abort. If any message is not
  coherent to the rest then abort.
  \FOR{$j := 1$ \TO $n$, $j \neq i$}
    \IF{$b_j$ is not a bit commitment of $k_j$}
      \STATE Abort protocol.
    \ENDIF
  \ENDFOR
  \STATE $k \leftarrow k_1 \oplus \ldots \oplus k_n$
\end{algorithmic}
  \caption{Distributed key generation algorithm generating random key $k$}
  \label{alg:key_gen_alg}
\end{algorithm}

An example of this protocol for 3 registrars is shown in
\ref{fig:key_gen_example}.

\begin{figure}
\begin{msc}{Distributed key-generation}
\setlength{\instdist}{5.5cm}
\setlength{\envinstdist}{3cm}
\declinst{ra}{}{RA}
\declinst{rb}{}{RB}
\declinst{rc}{}{RC}
\action*{
\begin{minipage}{4cm}\centering
  Generate random key $r_A$ and generate bit-commitment string for that key:
  $h_A$.
\end{minipage}}{ra}
\nextlevel[5]
\mess{}{ra}{rb}
\mess{$(h_A)_A$}{ra}{rc}
\nextlevel[2]
\mess{$(h_B)_B$}{rb}{ra}
\nextlevel[2]
\mess{$(h_C)_C$}{rc}{ra}
\nextlevel[2]
\mess{}{ra}{rb}
\mess{$((h_A)_A, (h_B)_B, (h_C)_C)_A$}{ra}{rc}
\nextlevel[2]
\mess{$((h_A)_A, (h_B)_B, (h_C)_C)_B$}{rb}{ra}
\nextlevel[2]
\mess{$((h_A)_A, (h_B)_B, (h_C)_C)_C$}{rc}{ra}
\nextlevel[2]
\mess{}{ra}{rb}
\mess{$(r_A)_A$}{ra}{rc}
\nextlevel[2]
\mess{$(r_B)_B$}{rb}{ra}
\nextlevel[2]
\mess{$(r_C)_C$}{rc}{ra}
\nextlevel[2]
\action*{
\begin{minipage}{4cm}\centering
  If messages are consistent generate key $r := r_A \oplus r_B \oplus r_C$.
\end{minipage}}{ra}
\nextlevel[4]
\end{msc}
\caption{Example of distributed key-generation for 3 registrars}
\label{fig:key_gen_example}
\end{figure}

The protocol uses $O\left(n^2\right)$ messages and is vulnerable to an attack in
which an attacker simply does not participate in it. However in the large scope
of the system it's not an issue, because we assume that introducing a registrar
requires an organizational approval which is a nontrivial barrier of entry and
later any malicious nodes may be easily detected and removed from the
centralized lists should it become compromised.

\subsection{Node join protocol}

Every node in order to participate in the DHT network is required to have a
collection of node certificates from registrars. Certificate serves as a proof
to other nodes that the key in the node ID has been generated by that
registration authority and that the registration authority allowed this node to
join the DHT.

The node join protocol is started by a DHT node that wants to join the network.
Upon its successful completion the node acquires a DHT key generated by
registrars and a collection of certifcates tying that DHT key to his public key.

The system's threat model allows some registration authorities to be malicious
and potentially generate biased keys. The node join protocol prevents such nodes
from performing a successful attack. Ghoul takes a constant $m$ as a parameter 
indicating maximal number of malicious registrars. The node join protocol then
requires that at least $m+1$ certificates are present for the node to be
considered valid.

The protocol is a combination of the challenge protocol and distributed random
number generation. Client node contacts any registrar requesting a challenge and
combines its solution with a join request. Then the registrar chooses $m$ other
registrars and generates random number with them. At the end all participating
registrars send their certificates.

In figure~\ref{fig:node_join_prot} an example of the node join protocol is shown
for $m=1$.

\begin{figure}
\begin{msc}{Node join protocol}
\setlength{\instdist}{5.5cm}
\setlength{\envinstdist}{3cm}
\setlength{\instwidth}{2.5cm}
\declinst{client}{C}{Client}
\declinst{ra}{RA}{Registrar A}
\declinst{rb}{RB}{Registrar B}
\nextlevel
\referencestart{c}{challenge protocol}{client}{ra}
\nextlevel[5]
\mess{send solution and request join}{client}{ra}
\nextlevel
\referenceend{c}
\nextlevel[1]

\action*{
\begin{minipage}{4cm}\centering
  choose $m$ registrars to perform random number generation
\end{minipage}}{ra}

\nextlevel[6]

\mess{\parbox{4.5cm}{start number generation \\ for C with A, B\\}}{ra}{rb}

\nextlevel


\referencestart{r}{robust key-generation protocol}{ra}{rb}
\nextlevel[2]
\gate[r][b]{out}{rleft}
\mess{\parbox{4cm}{node certificates \\ signed by A and B\\}}{rleft}{client}
\nextlevel[1]
\referenceend{r}
\end{msc}
\caption{Node's join protocol}
\label{fig:node_join_prot}
\end{figure}

\paragraph{Certificate refresh} Once a certificate has been generated it is
valid only for some time. Every node that has a valid certificate that has not
been revoked may request a new certificate for the same (public key, dht key)
pair. To do this it contacts the registrar responsible for given certificate,
solves a challenge, and then sends a request for certificate update. In this
request it attaches the certificate in question. As a result the registrar sends
an updated certificate if it is still valid.

Certificate refresh is a necessary part of the protocol, since without it each
node would have to join the network again upon its expiration. It unnecessarily
induces churn and provides a vulnerability for an eclipse attack. The eclipse
attack vulnerability stems from the fact that in Kademlia it is hard to flush
out an old, active node from the routing table. This behavior is used in KAD to
prevent an attacker, who might even have large number of IDs, to overwrite data
that sits in the table by spamming the node in question hoping to replaced the
older honest. If we force every node to reentry upon expiration date then the
natural Kademlia defense is rendered void.

\subsection{Certificate revocation system}

One of the advantages of a centralized certificate issuers is that they can
revoke certificates. Typical distributed scheme only offers a local protection:
a node that detects malicious behavior simply discards the offender from its
routing table, the malicious node may still contact other oblivious nodes. With
revocation it is possible to eliminate offenders globally, drastically
increasing a cost of an attack.

A certificate revocation looks the same as a certificate, that is it is a
tuple:\\
(\texttt{NODE\_PUB\_KEY},~\texttt{NODE\_DHT\_KEY},~\texttt{EXPIRATION\_DATETIME})
signed by a registrar. This tuple means that certificate for given pair is no
longer valid and it should be removed from a routing table and its messages
should be discarded. Each registrar maintains its own revocation list and each
DHT node should periodically synchronize this list with its own copy.
Certificate revocations are destroyed after the certificate they revoke is no
longer valid. That's what is meant by the expiration date.

TODO
[Wersje: Pobieramy bezposrednio lub teÅ¼ plotkujemy]
[Wersje: MoÅ¼e jakiÅ› merkle tree, bloom filter]
[Wersje: Challenge lub bez challenge'u

\subsection{SybilControl - Limiting number of Sybil nodes with computational
puzzles}
\subsubsection{Goals}
  Verifiable random key generation in Kademlia is a defense against eclipse
  style attacks, which in Kademlia are much harder to launch than in other
  DHTs, such as Chord, due to non-strict routing tables and redundant, iterative
  routing algorithm. Unless attacker has access to a large number of nodes it is
  difficult to launch an successful eclipse attack \cite{mac09}. Therefore for
  Ghoul to be secure a protection scheme against a Sybil attack is necessary.
  Although the scope of such an attack will be limited by the centralized
  authority, thanks to the use of computation puzzles, only the rate of
  entry is limited. It's still possible to accumulate Sybil nodes over time.

  The centralized authority allows for implementation of various anti-Sybil
  check schemes, but such a scheme would increase responsibilities of those
  nodes which we might want to keep as simple as possible. So in order to
  provide a defense against Sybil attack Ghoul incorporates SybilControl into
  its mechanisms.

\subsubsection{SybilControl mechanism}
  SybilControl is fully described in \cite{li12}. Here I will describe the core
  mechanism as it is used in Ghoul. 

  To limit the number of Sybil nodes SybilControl requires that nodes
  periodically generate a cryptographic puzzle and solve it. To verify that
  this puzzle is generated honestly it includes similarly generated puzzles
  propagated from its neighbors. Let's call the puzzle string for node $A$ as
  $C_{A-new}$. Assuming $A$ has received puzzles $C_{B_i}$ from its neighbors
  $B_{i}$, then $C_{A-new}$ is:

  \begin{eqnarray*}
      R_{A-new} &=& B_1||C_{B_1}||\ldots||B_n||C_{B_n}||r_A||C_{A-old}\\
    C_{A-new} &=& H\left(R_{A-new}\right)
  \end{eqnarray*}

  $r_A$ is a random string generated by $A$. $C_{A-old}$ is the previous puzzle
  generated by $A$. $H$ is a one-way function such as \texttt{SHA-2}. This is to
  ensure that $r_A$ is not specially prepared to make the puzzle solving easy.

  The solution to the puzzle is such a string $S$ that:

  \[ h = H\left(A||C_A||S\right)\]

  has at least $p$ last bits equal to zero.

  The entire puzzle state $P$ consists of: the solution $S_P$, the challenge
  $C_P$ and the record state $R_P$. Generated puzzle states are kept for some
  globally defined time for verification purposes.

  \paragraph{Neighbor node verification}
  To verify that a neighbor node $B$ of $A$ has done its proof-of-work it is
  asked to send its latest puzzle state $P_B$. Then the asking node checks
  whether this is a valid, solved puzzle state and that it includes one of
  recent puzzles generated by $A$. Successful check means that $B$ has done some
  work recently and may be treated as an honest node.

  \paragraph{Non-neighbor node verification}
  To verify that a non-neighbor node has solved its puzzle in the recent past we
  need to check that our recent challenge has influenced its puzzle. To do that
  we find a path between us and the non-verified node. We query nodes in the
  path for their puzzle state history. The node verification is then equivalent
  to finding out in these puzzle state histories all puzzles that have
  influenced the puzzle of the node under verification. The node is verified iff
  a puzzle that we have recently produced is among them.

\subsubsection{SybilControl vulnerabilities}
  Authors of the SybilControl paper did not consider some pernicious
  vulnerabilities, which may break the protocol. Here I will describe what they
  are and how does Ghoul deal with them.

  First off the protocol loosely defines what constitutes a neighbor. An
  uncareful implementation of SybilControl in which every cryptographic puzzle
  propagation is included in the generation of the next puzzle may increase the
  size of the puzzle size considerably. This kind of behavior may be used to
  slow down the DHT by nodes which gratuitously send challenge updates to all
  nodes in the DHT. Li et al. do not take this into consideration. This can
  be prevented by including only challenges received from verified nodes, such
  as nodes in the routing table, and additionally limiting the number of
  included challenges to those that have been received in the last $2p$ seconds
  from the $i$ closest nodes. Where $p$ and $i$ are globally defined constants.

  Secondly non-neighbor node verification requires collaboration from
  intermediate nodes, failing nodes may cause the check to fail and malicious
  nodes may even try to incriminate an honest node. A malicious node may
  correctly participate in the DHT, but when it is an intermediate node in
  SybilControl check it might drop the query. Although Kademlia uses redundant
  routing, such an attack may cause a snowballing effect over time. To prevent
  that behavior the direct and non-direct check need to be indistinguishable.
  If those checks are indistinguishable an attacker who drops SybilControl
  queries causes other nodes to consider him malicious and remove him from
  routing tables.

  To make queries indistinguishable we define only one SybilControl query
  message: \texttt{SC\_QUERY}, which is parametrized by a searched key. Its
  response should be a collection of nodes closest to given key and the history
  of puzzle states of the recipient. Direct verification simply looks at the
  latest puzzle in the history and discards all the other information.
  Non-direct check uses the found key for typical find node operation and also
  the history for SybilControl verification. In fact in this scheme there's no
  need for distinguishing direct and non-direct verification from the point of
  view of the verifier.

\subsubsection{SybilControl in Ghoul}
  SybilControl requires additional consideration as to how it integrates with
  Kademlia.

  The protocol described in SybilControl has only local effects, that is a node
  that does not have an up-to-date puzzle will just not be included into the
  routing table. Since Ghoul uses a certification system with revocation it is
  possible for nodes to complain about others to registrars. If registrars find
  that given node is malicious or Sybil they may globally revoke its
  certificate.

  The size of the SybilControl query also needs to be considered. Usually a
  Kademlia implementation uses UDP protocol for message sending. This means that
  the maximal size of a single message is 64KB. This gives us a bound on the
  SybilControl query response. Assuming likely value of keeping 10 last puzzle
  states in history this means we have 6.4KB for one puzzle state record.
  Kademlia key and challenge ($B_i || C_{B_i}$) are of size $160 + 16$ or $160
  + 32$ bytes, that is around 200 bytes. Which forces us to consider only 32
  neighbor challenges when building a our puzzle. Perhaps even a little bit
  less to accommodate other metadata. The \texttt{SC\_QUERY} is the only message
  that has potential to be too large if unconsidered.

\section{Summary}
\label{sec:ghoul_summary}
  This section concludes the specification of Ghoul. Here I will evaluate its
  strengths and weaknesses.
  
  \subsection{Security}
  The core advantage of this design is that it secures the DHT from Sybil and
  eclipse attacks while at the same time it does not take any additional
  assumptions about available resources apart from computing power. Ghoul does
  not assume anything about security properties of IP address or other network
  characteristics or require a Social network, or establishment of symmetric key
  architecture.  This means that setting up Ghoul does not require any more work
  than setting up a bare Kademlia implementation, sometimes even less since some
  protection schemes stop working for users behind NAT.

  Keeping the completely abstract nature of identification makes it possible to
  augment this scheme with other security protocols. Application programmer may
  augment the scheme anonymization, using transport-level protocols like Tor or
  DHT-level solution like Octopus~\cite{wan12b}.

  Ghoul ensures that keys are generated fairly and that every node performs
  periodic proof-of-work, which limits the size of a Sybil attack. This coupled
  with natural redundancy of Kademlia protocol also make launching an eclipse
  attack much harder.

  Ghoul, however is not invulnerable and has a few weaknesses:

  \begin{description}
    \item{\textbf{anonymization}} Lack of anonymization gives a snooping
      attacker a possibility to acquire information about node's behavior and
      use it to augment his attack. For example if an attacker can predict
      whether node verification in the SybilControl scheme is direct or not then
      this whole scheme is rendered void.
    \item{\textbf{denial of service}} Additional security mechanisms increase
      amount of work a node can and needs to perform. If nodes do not limit this
      a crafty attacker may congest a node with specially defined behavior. One
      pernicious example of this class of attack is attack on the certificate
      revocation scheme. An attacker might introduce a large number of correctly
      behaving nodes in the system, who after some time start behaving
      maliciously. This is detected by Ghoul and their certificate's are
      revoked. On first sight this is a desired behavior, but if the number of
      such nodes is very large then the revocation list become large as well.
      Since each DHT node will try to synchronize this list it may generate
      traffic large enough to congest it.
  \end{description}

  \subsection{Performance}

  Ghoul focuses on changing node join and neighbor addition protocol and as
  such does not change anything else. Especially a typical use of Kademlia for
  finding nodes or data does incur any performance penalty.

  Node join protocol changes an instantaneous operation into a small distributed
  protocol with some proof-of-work. Since this happens only once its cost is
  negligible. From the point of view the central authority the node join
  protocol requires it to only be able to generate and save nonces and perform
  the distributed key generation algorithm. Since node's join happens only once
  in the existence and those operations are lightweight then it means that the
  central authority can be a simple machine and should not be a performance
  bottleneck.

  The biggest performance overhead happens during neighbor addition when
  verification is performed. The verification message complexity is on the order
  of $O(\log n)$ and requires sending larger messages. This exacerbates effects
  of churn and the network will take longer time to adapt to topology changes.
  A more detailed analysis of SybilControl's impact on DHT behavior can be
  found in \cite{li12}..

  Since Ghoul uses computational resources for proof-of-work verification
  therefore this parameter requires careful tuning. Application designer needs
  to consider the weakest node that should be able to join the DHT and also be
  aware that a Sybil attacker may create as many identities as is the factor
  of his computing power compared to the weakest node. Therefore tests with
  small hardness may prove to be ineffective in blocking an attack. On the other
  hand a weak node may still use Ghoul without performing any additional work,
  so we can only consider more powerful ones for creating the DHT.

  \subsection{Centralized key-generation}
  
  The inclusion of centralized authority looks like a step in the wrong
  direction. Central points of responsibility usually mean greater chance of
  systematic failure, lesser security, and non-scalable performance. I'd like to
  adress those three points.

  Successful Peer-to-Peer applications, like BitTorrent or Bitcoin, are not
  fully distributed, but use centralized services to provide a functional
  ecosystem. The file-sharing part of BitTorrent is distributed, but for 
  torrent search and metadata download users still use trackers. Those
  centralized servers are set up by a third-party and have total authority over
  their behavior. The reason why this set up works seamlessly is that
  there is not one central server, but multiple independent authorities. If a
  tracker starts behaving maliciously then it is noticed and search browsers do
  not return links to the malicious tracker. Similar set up is done in Ghoul.

  Additionally introduction of central authority is necessary for efficient
  security. Gatekeeper servers ensure that distributed keys are truly random,
  something that would be inefficient in distributed setting. Centralized
  cetrification system allows adding extensions and boost security mechanism
  which can recognize malicious nodes.

  The gatekeeper functionality in Ghoul is only used for node join and doesn't
  require any complex computational power. Even if node join fails or becomes
  congested the network is still usable. Already certfied nodes may still
  operate normally and external nodes may use it for node-search.
