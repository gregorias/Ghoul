\chapter{Ghoul system description}

In this chapter I present Ghoul's design. Section \ref{sec:ghoul_goals}
describes the problem that Ghoul solves and its assumptions. Section
\ref{sec:ghoul_overview} provides an overview of the protocols used in Ghoul.
Sections \ref{sec:ghoul_data} and \ref{sec:ghoul_protocols} describe in detail
Ghoul's mechanisms - its data structures and protocols. The final section
\ref{sec:ghoul_summary} describes Ghoul's strengths and weaknesses..

\section{Goals}
\label{sec:ghoul_goals}
I decided to build Ghoul to fill a niche of secure open-source DHT network
implementation. In my experience it is difficult to find a satisfactory
open-source implementation of Kademlia DHT. By satisfactory I mean one that
satisfies all of the following criterias:

\begin{description}
  \item{\textbf{Single responsibility}} Implementation of Kademlia should do
    only one thing: operate according to the Kademlia protocol.
  \item{\textbf{Extensibility}} Extension of the network protocol with a
    NAT traversal mechanism should not require modification of a large portion
    of the library's network communication stack.
  \item{\textbf{Documentation}} An open-source project should have maintained
    documentation to help others contribute or use it.
  \item{\textbf{Robustness}} Implementation should not fail after it is used
    for 1 hour on a small network consisting of a hundred nodes.
\end{description}

I couldn't find an implementation that satisfies all of the above in Java and
none that would satisfiably claim to be secure in any language. Some examples
that I have considered are:
openkad\footnote{\texttt{https://code.google.com/p/openkad/}}, which does not
implement DHT storage operations, TomP2P\footnote{\texttt{http://tomp2p.net/}},
which never worked without a failure, even after a few bug patches, and
JoshuaKissoon/Kademlia
\footnote{\texttt{https://github.com/JoshuaKissoon/Kademlia}}, which is not
extensible.

Solutions used in KAD network and designed for Mainline DHT use IP addresses to
prevent Sybil attack and arbitrary ID choice. This approach works against
unsophisticated attacker, but has problems stemming from the fact that IP was
not designed for that use case. IP spoofing, IPv6 privacy extensions and lack of
anonymity are serious concerns that either neutralize such solution or introduce
a serious flaw. I feel that lack of adoption of security measures that are
present in the research literature stems from the stereotype that such measures
are either hard to implement, slow, hard to satisfy their dependencies, or
needlessly complicate use of the application. With Ghoul I show that it is
possible to design and build a DHT that satisfies following constraints:

\begin{description}
  \item{\textbf{Security}} The DHT should be resistant to Sybil and
    eclipse attacks.
  \item{\textbf{Performance}} The DHT should be as performant as the original
    protocol where possible, especially in common use cases of finding a node,
    storing and getting. In other cases the time of operation should be
    practical, meaning that time or message complexity should not be greater
    than $O(\log n)$ for network of size $n$.
  \item{\textbf{Simplicity}} The DHT should be simple to use. User should not be
    forced to perform an extensive set up, or prepare a large configuration file
    to just start the DHT.  The entire scheme should be simple to describe. User
    or developer should be able to understand how the protection schemes work
    and be able to reason how it would behave in his application.
  \item{\textbf{Extensibility}} Application developers should be able to extend
    the system with their own security mechanism easily.
  \item{\textbf{Anonymity}} The security mechanism should not compromise user
    anonymity.
\end{description}

I assume standard threats and network conditions that is:

\begin{itemize}
  \item An attacker may introduce colluding nodes into the system, but has
    limited computing and communication power.
  \item There is only a point-to-point message passing primitive for network
    communication. Delivery time is not bounded and mail fail altogether.
  \item Nodes may exhibit byzantine failure.
\end{itemize}

\section{Overview}
\label{sec:ghoul_overview}
Ghoul is extends the Kademlia DHT protocol. Each node in the system is an
independent agent which acts as a Ghoul node and communicates with other nodes
using messages sent over a network.

There are two kinds of nodes in the system: a DHT node and a registration
authority. A DHT node is a Kademlia node extended with security measures.
It initiates and maintains its routing table and answers queries. Additionally,
each DHT node is responsible for maintaining the security of the entire network
by participating in P2P certificate revocation propagation, maintaining its
security certificate, and responding to security queries.

A small set of nodes, called registration nodes, is responsible for facilitating
node’s join into the network by using distributed random key generation and
certificate issuance. Registration nodes are a distributed version of central
authority, with a twist that a few of them might be malicious. Their existence
is motivated by the fact that it is very hard to guarantee random key generation
and verification in a fully distributed setting. On the other, it is desirable
for the system to have at least administrative scalability. Application's owner
should be able to allow other parties to provide their registration nodes for
the protocol. Users should not worry whether registration nodes have
non-malicious intentions. The registration protocol works correctly as long as a
single node is honest.

\section{Data structures}
\label{sec:ghoul_data}

\subsection{Public key cryptography}
Ghoul uses public key cryptography for node authentication and certification.
Every DHT node and every registration node generates a public/private key pair
on its first entry. The private key is always kept private. The public key will
be propagated. Additionally, public keys of registration nodes are known by all
nodes.

To participate in the network a DHT node requires a \textbf{certificate}.
A certificate is a tuple consisting of:
(\texttt{NODE\_PUB\_KEY},~\texttt{NODE\_DHT\_KEY},~\texttt{EXPIRATION\_DATETIME})
signed with a registration node's private key such that it is known which node
signed it. Such a certificate is given by the registration node together with
\texttt{NODE\_DHT\_KEY}. The certificate serves as a proof that the node is
valid and its key was generated randomly by a set of registration nodes. If the
key is generated by a group of registration nodes then each of them provides a
separate certificate.

We say that a node is valid if it has at least $m + 1$ non-expired, non-revoked
certificates generated by different registration nodes. The parameter $m$ should
be set to such a value that we are sure that there can be at most $m$ malicious
registration nodes.

Every node maintains a store for valid certificates that it has received from
other nodes. This store may be limited in size. In such a case a node may remove
certificates of the last seen node or certificates close to expiration.
Additionally every node in the routing table must have a valid certificate in
the store, otherwise the node should be removed from the routing table. If a
certificate of a Kademlia's neighbor is close to expiration then a
\texttt{PING} should be sent to get an updated certificate.

\subsection{Messages}
Ghoul extends each DHT message with following fields:
\begin{description}
  \item{\texttt{certificateRequest}} Signifies that a response to this message
    should contain a list of certificates. This field is set when the recipient
    is considered to be a neighbor or potential neighbor and either its
    certificates are not present, not valid, or close to expiration.
  \item{\texttt{certificates}} A list of valid certificates provided by the
    registration authority.
  \item{\texttt{signature}} A message signature signed with the sender's private
    key.
\end{description}

Those fields are piggybacked on normal Kademlia messages. The size of
\texttt{certificateRequest} and \texttt{signature} is negligible.
\texttt{certificates} field may have large size, where each certificate has a
size of $\approx$ 1KB. Fortunately, the list of certificates is sent
sporadically.

Each one of those additional fields is optional. If the signature field is not
provided it means that the node is not interested in being part of the network
and instead just uses it to find information. That is considered normal
behavior. Such node is not added to its interlocutor's routing table as such a
node doesn't even have to provide its DHT key. Such signatureless queries
will only be responded with requested information.
Otherwise every node should always sign its messages.

The \texttt{certificateRequest} field is set if all of the following conditions
are met:

\begin{itemize}
  \item The recipient's certificate is not present in the sender's store or is
    close to expiration.
  \item The recipient is in the routing table or may be considered a candidate.
\end{itemize}

If the \texttt{certificateRequest} field is set then the recipient should attach
a list of ts certificates to its response. If no response would be normally
given then it should respond with a \text{PONG} message.

If a response to the message with the \texttt{certificateRequest} does not have
a valid list of certificates then it is discarded.

\section{Protocols}
\label{sec:ghoul_protocols}
\subsection{Challenge protocol}
In some neuralgical and vulnerable points in the protocol we may intent to limit
the number of requests a node can make using cryptographic challenges. This
limit achieves two goals: It significantly increases the cost of an attack which
relies on number of queries, such as a Sybil attack; it provides a throttle
mechanism to prevent a node overload.

Whenever the protocol requires the node sending a query or a request to provide
a proof-of-work for this request the challenge protocol is used
(Fig. \ref{fig:chal_prot}).

\begin{figure}
\begin{msc}{Challenge protocol}
\setlength{\instdist}{9cm}
\setlength{\envinstdist}{3cm}
\declinst{client}{C}{Client}
\declinst{server}{S}{Server}
\mess{Send a challenge request}{client}{server}
\nextlevel
\action*{
\begin{minipage}{4cm}\centering
Choose a random nonce\\
$r\in\{0,1\}^*$,\\ difficulty $p \in \N$,\\ $t := \text{current time}$.
\end{minipage}}{server}
\nextlevel[6]
\mess{Send challenge $m_2 := (t, r, p)_{s_{pr}}$}{server}{client}
\nextlevel[1]
\action*{
\begin{minipage}{4cm}\centering
  Find $s$ such that $H(r || s)$ has $p$ last bits equal to zero.
\end{minipage}}{client}
\nextlevel[5]
\mess{Send solution $m_3 := (m_2, s)$}{client}{server}
\nextlevel
\action*{
\begin{minipage}{4cm}\centering
Check the validity of the solution. Save $r$ into the active puzzles list
until the validity of the puzzle has ended.
\end{minipage}}{server}
\nextlevel[5]
\end{msc}
  \caption{Challenge protocol}
  \label{fig:chal_prot}
\end{figure}

The client initiates the protocol by sending a challenge request to the server. 
Upon receiving a request the server chooses the difficulty $p$ of the challenge
and a random nonce $r$. The server send the challenge $m_2$ consisting of $r$,
$p$, and current time on the server: $t$. $m_2$ is signed with server's private
key.  The client now has to find such a number $s$ that its concatenation with
$p$ ($p || s$) has a hash with $p$ last bits equal to zero. When such $s$ is
found then the client sends a message $m_3$ with the challenge $m_2$ and the
solution $s$. The server then checks the validity of the solution.

The validity check consists of: verifying signature of $m_2$, checking whether
nonce is not in the active puzzles list, checking time, verifying the hash of
the solution.

$m_3$ serves as a proof-of-work and may be accompanied by an additional request
to the server.

There is a variant to this scheme in which the server saves distributed nonces
and later checks that they exist in the distributed nonces list during
verification. Depending on the duration of the timeout and number of possible
queries per second this variant may provide a denial-of-service vulnerability.

\subsection{Robust distributed random key generation}

In Ghoul honesty of registrars is not assumed. A single centralized
registrar would greatly facilitate an eclipse attack by assigning to colluding
nodes keys close to a target. This vulnerability  calls for a verifiable
distributed scheme of key generation.

Here I will present a distributed protocol which generates a random key that is
unbiased if at least one node is honest. More formally:

\begin{theorem}
  Let $R = \langle r_1, \ldots, r_n \rangle$ of $n \geq 2$ be a list of nodes
  participating in the random key generation protocol. All nodes in $R$ know
  $R$. 
  If all nodes respond according to the protocol in a timely manner and at least
  one node is honest, then the protocol generates one, unbiased, random key known
  to all participants.
  If some nodes exhibit byzantine failure, but at least one non-failing node is
  honest, then all nodes that generate a key generate the same, unbiased key.

  The chance that a malicious participant manipulates the protocol so that this
  theorem does not hold is cryptographically negligible.
  \label{th:robust_distributed_key_generation}
\end{theorem}

The protocol that satisfies those properties is defined in
\ref{alg:key_gen_alg}.  It uses bit-commitment scheme which is defined as
follows:

\begin{defin*}[Bit-commitment]
  Bit-commitment \cite[p.220]{gol08} is a cryptographic protocol that allows one
  to commit a value such that it is hidden and the commitment may be shared with
  each participant. Later the commiter may reveal the commited value to
  participants in such a way that they can verify that it is indeed hidden in
  the commitment shared earlier .

  Typical bit-commitment use is split into two phases:
  \begin{description}
    \item{\textbf{Hiding phase}} Commiter chooses a value and creates a
      commitment which hides the value. The commiter sends the commitment to
      interested parties.
    \item{\textbf{Reveal phase}} The value and the key used to create the
      commitment are revealed. Interested parties may check that they are
      consistent with earlier commitments.
  \end{description}

  Bit-commitment protocols belong to two disjoint sets: unconditionally binding
  commitments and unconditionally hiding commitments.
  Unconditionally binding means that even computationally unbounded commiter may
  not reveal a different value than the one commited. 
  Unconditionally hiding means that any value is equally likely to be hidden in
  the commitment, i. e. no participant may find out the commited value based
  only on the commitment.
\end{defin*}

The random number generation protocol consists of 3 phases:
\begin{enumerate}
  \item (Lines 1-5) Commit and broadcast a random number used to generate the
    key. This phase is used so that every node commits to its random number and
    cannot change it later.
  \item (Lines 6-9) Broadcast all received messages to others with the
    commitment key. This step ensures that every honest node has received the
    same set of messages and will generate the same key. If any node has sent
    inconsistent messages to honest
    nodes, then this will be detected in this stage.
  \item (Lines 10-16) Verify correctness of messages and output the generated
    key.
\end{enumerate}

One may recognize that this protocol consist of the first two phases of a
3-phase byzantine failure protection protocol. Which is the reason why it has
its non-malleability properties.

\begin{algorithm}[tb]
  \begin{algorithmic}[1]
  \STATE $k_i \leftarrow $ random key
  \STATE $(h_i, s_i) \leftarrow $ bit commitment string and solution commiting
  $k_i$
  \FOR{$j := 1$ \TO $n$, $j \neq i$}
    \STATE Send $(h_i)_{i}$ to $r_j$
  \ENDFOR
  \STATE Wait $T$ seconds till all messages of the form $(h_j)_j$ are received
  from other nodes. If timeout happens then abort.
  \FOR{$j := 1$ \TO $n$, $j \neq i$}
    \STATE Send $\left( (h_1)_1, \ldots, (h_n)_{n}, k_i, s_i\right)_i$ to $r_j$
  \ENDFOR
  \STATE Wait $T$ seconds till all messages of the above form are received
  from other nodes. If timeout happens then abort. If any message is not
  coherent to the rest then abort.
  \FOR{$j := 1$ \TO $n$, $j \neq i$}
    \IF{$b_j$ is not a bit commitment of $k_j$}
      \STATE Abort protocol.
    \ENDIF
  \ENDFOR
  \STATE $k \leftarrow k_1 \oplus \ldots \oplus k_n$
\end{algorithmic}
  \caption{Distributed key generation algorithm generating random key $k$}
  \label{alg:key_gen_alg}
\end{algorithm}

An example of this protocol for 3 registrars is shown in figure
\ref{fig:key_gen_example}.

\begin{figure}
\begin{msc}{Distributed key-generation}
\setlength{\instdist}{5.5cm}
\setlength{\envinstdist}{3cm}
\declinst{ra}{}{RA}
\declinst{rb}{}{RB}
\declinst{rc}{}{RC}
\action*{
\begin{minipage}{4cm}\centering
  Generate random key $r_A$ and generate bit-commitment string for that key:
  $h_A$.
\end{minipage}}{ra}
\nextlevel[5]
\mess{}{ra}{rb}
\mess{$(h_A)_A$}{ra}{rc}
\nextlevel[2]
\mess{$(h_B)_B$}{rb}{ra}
\nextlevel[2]
\mess{$(h_C)_C$}{rc}{ra}
\nextlevel[2]
\mess{}{ra}{rb}
\mess{$((h_A)_A, (h_B)_B, (h_C)_C)_A$}{ra}{rc}
\nextlevel[2]
\mess{$((h_A)_A, (h_B)_B, (h_C)_C)_B$}{rb}{ra}
\nextlevel[2]
\mess{$((h_A)_A, (h_B)_B, (h_C)_C)_C$}{rc}{ra}
\nextlevel[2]
\mess{}{ra}{rb}
\mess{$(s_A)_A$}{ra}{rc}
\nextlevel[2]
\mess{$(s_B)_B$}{rb}{ra}
\nextlevel[2]
\mess{$(s_C)_C$}{rc}{ra}
\nextlevel[2]
\action*{
\begin{minipage}{4cm}\centering
  If messages are consistent generate key $r := r_A \oplus r_B \oplus r_C$.
\end{minipage}}{ra}
\nextlevel[4]
\end{msc}
\caption{Example of distributed key-generation for 3 registrars}
\label{fig:key_gen_example}
\end{figure}

The protocol uses $O\left(n^2\right)$ messages and is vulnerable to an attack in
which an adversary simply does not participate in it. However in the large scope
of the system it's not an issue, because we assume that introducing a registrar
requires an organizational approval which is a nontrivial barrier of entry and
later any malicious nodes may be easily detected and removed from the
centralized lists should it become compromised.

\subsubsection{Proof of theorem \ref{th:robust_distributed_key_generation}}

If node $A$ has reached stage 3 that means that every node had completed stage 1
and all messages from stage 1 had been received. Indeed, in line 10 the node $A$
had waited for all stage 2 broadcast messages, which can only be received if
the sender has received all messages from stage 1.
Therefore, if any node generates a key, then all nodes have successfully passed
stage 1.

Careful reader will notice that we need to prove that the protocol is resistant
to a replay attack. An adversary $A$ may remember messages sent by an honest
node $B$ in earlier runs of the protocol. $A$ may try to replace the message
sent by $B$, $\left(h_B\right)_B$, with an older message: $\left(h_B'\right)_B$.
However if that happens then the adversary will also have to generate a valid
stage 2 message signed with $B$'s private key: 
$\left(\left(h_1\right)_1, \ldots, \left(h_B'\right)_B, \ldots,
\left(h_n\right)_n\right)_B$
Since the adversary tries to fool an honest node and $h_i$ values are
effectively random (if $i$ is honest), therefore the adversary won't be able to
do so.
Notice that if we would try to save bandwith and not include
$\left(h_i\right)_i$ in the stage 2 message sent to $i$, then the replay attack
would work.

If a key is generated from values $\left(k_i\right)_{1 \leq i \leq n}$, then the
key is unbiased. Indeed, if $r$ is uniformly random variable and $s$ is any
random variable, then the function: $r \oplus s$ is also a uniformly random
variable. So ,if at least one value $k_j$ has been chosen randomly, then $k$ is
an unbiased random key.

Finally, we have to prove that all keys produced by honest nodes are the same.
This means that the view $k_1, \ldots, k_n$ of each of those honest nodes is the
same. The view might be different only if an adversary manages to send different
(but consistent) messages to different nodes.Since we have already proven that the
adversary may not replace a message from an honest node, therefore the adversary
may only manipulate its own messages. So assume that honest nodes $B$
and $C$ have received respectively: $\left(h_A\right)_A, \left(h_A'\right)_A,
h_A \neq h_A'$ from the adversary $A$.
This situation will be discovered in stage $2$ when $B$ and $C$ share their view
of commitments and they will abort their execution of the protocol.

\subsection{Node join protocol}

In order to participate in the DHT network, a node is required to obtain a
collection of node certificates from registrars. A certificate serves as a proof
to other nodes that the DHT key in the node ID has been generated by that
registration authority and that the registration authority allowed this node to
join the DHT.

The node join protocol is started by a node that wants to join the network.
Upon its successful completion the node acquires a DHT key generated by
registrars and a collection of certifcates tying that DHT key to the node's
public key.

The system's threat model allows some registration authorities to be malicious
and potentially generate biased keys. The node join protocol prevents such nodes
from performing a successful attack. Ghoul takes a system-wide constant $m$ as a
parameter indicating maximal number of malicious registrars. The node join
protocol requires that at least $m+1$ certificates are present for the node to
be considered valid.

The protocol is a combination of the challenge protocol and then distributed
random number generation protocol. The joining node contacts any registrar
requesting a challenge and combines its solution with a join request. Then the
registrar chooses $m$ other registrars and generates random number with them. At
the end all participating registrars send their certificates.

In figure~\ref{fig:node_join_prot} an example of the node join protocol is shown
for $m=1$.

\begin{figure}
\begin{msc}{Node join protocol}
\setlength{\instdist}{5.5cm}
\setlength{\envinstdist}{3cm}
\setlength{\instwidth}{2.5cm}
\declinst{client}{C}{Client}
\declinst{ra}{RA}{Registrar A}
\declinst{rb}{RB}{Registrar B}
\nextlevel
\referencestart{c}{challenge protocol}{client}{ra}
\nextlevel[5]
\mess{send solution and request join}{client}{ra}
\nextlevel
\referenceend{c}
\nextlevel[1]

\action*{
\begin{minipage}{4cm}\centering
  choose $m$ registrars to perform random number generation
\end{minipage}}{ra}

\nextlevel[6]

\mess{\parbox{4.5cm}{start number generation \\ for C with A, B\\}}{ra}{rb}

\nextlevel


\referencestart{r}{robust key-generation protocol}{ra}{rb}
\nextlevel[2]
\gate[r][b]{out}{rleft}
\mess{\parbox{4cm}{node certificates \\ signed by A and B\\}}{rleft}{client}
\nextlevel[1]
\referenceend{r}
\end{msc}
\caption{Node's join protocol}
\label{fig:node_join_prot}
\end{figure}

\paragraph{Certificate refresh} Once a certificate has been generated it is
valid only for some time. Every node that has a valid certificate that has not
been revoked may request a new certificate for the same (public key, dht key)
pair. To do this it contacts the registrar responsible for given certificate,
solves a challenge, and then sends a request for certificate update. In this
request it attaches the certificate in question. As a result the registrar sends
an updated certificate if it is still valid.

Certificate refresh is a necessary part of the protocol, since without it each
node would have to join the network again upon certificate expiration.
Fresh reentry unnecessarily induces churn and provides a vulnerability for an
eclipse attack. 
In Kademlia it is hard to flush out an old, active node from the routing table.
This behavior is used in KAD to prevent an attacker, who might even have large
number of IDs, to overwrite data that is stored in the table by spamming the
node in question hoping to replace the older value. If we force every node to
reentry upon expiration date then this natural Kademlia defense would be
rendered void.

\subsection{Certificate revocation system}

One of the advantages of a centralized certificate issuers is that they can
revoke certificates. Typical distributed scheme only offers a local protection:
a node that detects malicious behavior simply discards the offender from its
routing table. However, the malicious node may still contact other oblivious
nodes. With revocation it is possible to eliminate offenders globally,
drastically increasing the cost of an attack.

A certificate revocation has the same syntax as a certificate. It is a
tuple:\\
(\texttt{NODE\_PUB\_KEY},~\texttt{NODE\_DHT\_KEY},~\texttt{EXPIRATION\_DATETIME})
signed by a registrar. This tuple means that the certificate for given ID pair
is no longer valid. The revoked node should be removed from routing tables and
its messages should be discarded. Each registrar maintains its own revocation
list and each DHT node should periodically synchronize this list with its own
copy.
Certificate revocations are destroyed after the certificate they revoke is no
longer valid, i. e. the expiration date.

TODO
[Wersje: Pobieramy bezposrednio lub też plotkujemy]
[Wersje: Może jakiś merkle tree, bloom filter]
[Wersje: Challenge lub bez challenge'u

\subsection{SybilControl - Limiting number of Sybil nodes with computational
puzzles}
\subsubsection{Goals}
  Verifiable random key generation in Kademlia is a defense against eclipse
  style attacks, which in Kademlia are much harder to launch than in other
  DHTs, such as Chord, due to non-strict routing tables and redundant, iterative
  routing algorithm. Unless an attacker has access to a large number of nodes,
  it is difficult to launch an successful eclipse attack \cite{mac09}. Therefore
  for Ghoul to be secure a protection scheme against a Sybil attack is
  necessary.
  Thanks to the use of computation puzzles the scope of such an attack will be
  limited by the centralized authority.
  However, only the rate of entry is limited.
  It is still possible to accumulate Sybil nodes over time.

  The centralized authority allows for implementation of various anti-Sybil
  check schemes, but such a scheme would increase responsibilities of those
  authority nodes which we might want to keep as simple as possible.
  So in order to provide a defense against Sybil attack Ghoul incorporates
  SybilControl into its mechanisms.

\subsubsection{SybilControl mechanism}
  SybilControl is fully described in \cite{li12}. Here I will describe the core
  mechanism as it is used in Ghoul. 

  To limit the number of Sybil nodes SybilControl requires that nodes
  periodically generate a cryptographic puzzle and solve it. To verify that
  this puzzle is generated honestly it includes similarly generated puzzles
  propagated from its neighbors. Let's call the puzzle string for node $A$ as
  $C_{A-new}$. Assuming $A$ has received puzzles $C_{B_i}$ from its neighbors
  $B_{i}$, then $C_{A-new}$ is:

  \begin{eqnarray*}
      R_{A-new} &=& B_1||C_{B_1}||\ldots||B_n||C_{B_n}||r_A||C_{A-old}\\
    C_{A-new} &=& H\left(R_{A-new}\right)
  \end{eqnarray*}

  $R_{A-new}$ is called a record string.
  $r_A$ is a random string generated by $A$.
  $C_{A-old}$ is the previous puzzle generated by $A$.
  $H$ is a one-way function such as \texttt{SHA-2}.
  This is to ensure that $r_A$ is not specially prepared to make the puzzle
  solving easy.

  The solution to the puzzle is such a string $S$ that:

  \[ h = H\left(A||C_A||S\right)\]

  has at least $p$ last bits equal to zero.

  For node $A$ the entire puzzle state $P_A$ consists of: the solution
  $S_{P_A}$, the challenge $C_{P_A}$ and the record state $R_{P_A}$.
  Generated puzzle states are kept for some globally defined time for
  verification purposes.

  \paragraph{Neighbor node verification}

  Node $A$ to verify its neighbor's, $B$, proof-of-work, asks $B$
  to send its latest puzzle state $P_B$.
  Then $A$ verifies whether the response is a valid, solved puzzle state and
  that it includes one of recent puzzles generated by $A$.
  Successful verification means that $B$ has done some work recently and may be
  treated as an honest node.

  \paragraph{Non-neighbor node verification}
  To verify that a non-neighbor node $B$ has solved node $A$'s puzzle in the
  recent past $A$ needs to check that its recent challenge has influenced $B$'s
  puzzle. 
  To do that $A$ finds a path between $A$ and the non-verified node.
  $A$ queries nodes in the path for their puzzle state history.
  The node verification is then equivalent to finding out in these puzzle state
  histories all puzzles that have influenced the puzzle of the node under
  verification.
  The node is verified if and only if a puzzle that $A$ has recently produced is
  among them.

\subsubsection{SybilControl vulnerabilities}
  The SybilControl paper doesn't consider some pernicious vulnerabilities, which
  may break the protocol.
  Here I will describe what they are and how does Ghoul
  deal with them.

  First, the protocol loosely defines what constitutes a neighbor. An
  uncareful implementation of SybilControl in which every cryptographic puzzle
  propagation is included in the generation of the next puzzle may increase the
  size of the puzzle size considerably. This kind of behavior may be used to
  slow down the DHT by nodes which gratuitously send challenge updates to all
  nodes in the DHT.
  This can be prevented by including only challenges received from verified
  nodes, such as nodes in the routing table, and additionally limiting the
  number of included challenges to those that have been received in the last
  $2p$ seconds from the $i$ closest nodes (where $p$ and $i$ are globally
  defined constants).

  Second, non-neighbor node verification requires collaboration from
  intermediate nodes.
  Failing nodes may cause the check to fail and malicious nodes may even try to
  incriminate an honest node. A malicious node may correctly participate in the
  DHT, but when it is an intermediate node in SybilControl check it might drop
  the query. Although Kademlia uses redundant routing, such an attack may cause
  a snowballing effect over time. To prevent that behavior the direct and
  non-direct check need to be indistinguishable.  If those checks are
  indistinguishable an attacker who drops SybilControl queries causes other
  nodes to consider him malicious and remove him from routing tables.

  To make queries indistinguishable we define only one SybilControl query
  message: \texttt{SC\_QUERY}, which is parametrized by a searched key. Its
  response should be a collection of nodes closest to the given key and the
  history of puzzle states of the recipient.
  Direct verification simply looks at the latest puzzle in the history and
  discards all the other information.
  Non-direct check uses the found key for subsequent find node operations and
  also the history for SybilControl verification.
  In fact in this scheme there's no need for distinguishing direct and
  non-direct verification from the point of view of the verifier.

\subsubsection{SybilControl in Ghoul}
  SybilControl requires additional consideration as to how it integrates with
  Kademlia.

  The protocol described in SybilControl has only local effects.
  A node that does not have an up-to-date puzzle will just not be included in
  the routing table.
  Since Ghoul uses a certification system with revocation, it is possible for
  nodes to accuse others of misbehavior to registrars.
  If registrars find that given node is malicious or Sybil they may globally
  revoke its certificate.

  The \texttt{SC\_QUERY} is the only message that has potential to be too large
  if unconsidered.
  Usually a Kademlia implementation uses UDP for message sending.
  The maximal size of a single message is 64KB.
  This gives us a bound on the SybilControl query response.
  Assuming that the history keeps 10 last puzzles states; this means there is
  6.4KB for one puzzle state record.
  Kademlia key and challenge ($B_i || C_{B_i}$) are of size $160 + 16$ or $160 +
  32$ bytes, that is around 200 bytes.
  Which forces us to consider at most $6,400/200 = 32$ neighbor challenges when
  building a puzzle.
  The actual value of neighbor challenges should be less than $32$ to accomodate
  metadata.
\section{Evaluation}
\label{sec:ghoul_summary}
  This section concludes the specification of Ghoul. Here I will evaluate its
  strengths and weaknesses.
  
  \subsection{Security}
  The core advantage of this design is that it secures the DHT from Sybil and
  eclipse attacks while at the same time it does not take any additional
  assumptions about available resources apart from computing power. Ghoul does
  not assume anything about security properties of IP address or other network
  characteristics or require a Social network, or establishment of symmetric key
  architecture.  This means that setting up Ghoul does not require any more work
  than setting up a bare Kademlia implementation.

  Keeping the completely abstract nature of identification makes it possible to
  augment this scheme with other security protocols. Application programmer may
  augment the scheme anonymization, using transport-level protocols like 
  Tor~\cite{syv04} or DHT-level solution like Octopus~\cite{wan12b}.

  Ghoul ensures that keys are generated fairly and that every node performs
  periodic proof-of-work, which limits the size of a Sybil attack. This coupled
  with natural redundancy of Kademlia protocol also make launching an eclipse
  attack much harder.

  Ghoul, however is not invulnerable and we are aware of two weaknesses of
  bare Ghoul protocol:

  \begin{description}
    \item{\textbf{anonymization}} Lack of anonymization (adversiaries may easily
      associate requests with sending nodes) gives a snooping attacker a
      possibility to acquire information about node's behavior and use it to
      augment the attacker's attack.
      For example if an attacker can predict whether node verification in the
      SybilControl scheme is direct or not then this whole scheme is rendered
      void.
    \item{\textbf{denial of service}} Additional security mechanisms increase
      amount of work a node needs to perform.
      If nodes do not limit their workload a crafty attacker may congest a node
      with specially defined behavior.
      One pernicious example of this class of attack is attack on the
      certificate revocation scheme.
      An attacker might introduce a large number of correctly
      behaving nodes in the system, who after some time start behaving
      maliciously. This is detected by Ghoul and their certificates are
      revoked.
      On first sight this is a desired behavior, but if the number of such nodes
      is very large then the revocation list become large as well.
      Since each DHT node will try to synchronize this list it may generate
      traffic large enough to congest it.
  \end{description}

  \subsection{Performance}

  Ghoul changed jst node join and neighbor additions protocol and as
  such does not change anything else.
  In particular a typical use of Kademlia for finding nodes or data does not
  incur any performance penalty.

  Node join protocol changes an instantaneous operation into an inexpensive
  distributed protocol with some proof-of-work.
  Since this happens only once its cost is negligible.
  For the central authority the node join protocol requires the ability to
  generate and save nonces, and perform the distributed key generation
  algorithm.
  Since node's join happens only once in node's existence and those operations
  are lightweight then it means that the central authority can be a simple
  machine and should not be a performance bottleneck.

  The biggest performance overhead happens during neighbor addition when
  verification is performed. The verification message complexity is in the order
  of $O(\log n)$ and requires sending larger messages. This exacerbates effects
  of churn and the network will take longer time to adapt to topology changes.
  A more detailed analysis of SybilControl's impact on DHT behavior can be
  found in \cite{li12}..

  Since Ghoul uses computational resources for proof-of-work verification
  therefore this parameter requires careful tuning. Application designer needs
  to consider the weakest node that should be able to join the DHT and also be
  aware that a Sybil attacker may create as many identities as is the factor
  of his computing power compared to the weakest node. Therefore tests with
  small hardness may prove to be ineffective in blocking an attack. On the other
  hand a weak node may still query without performing any additional work,
  so we can only consider more powerful ones for creating the DHT.

  \subsection{Centralized key-generation}
  
  The inclusion of centralized authority looks like a step in the wrong
  direction. Central points of responsibility usually mean greater chance of
  systematic failure, lesser security, and non-scalable performance. I'd like to
  adress those three points.

  Successful Peer-to-Peer applications, like BitTorrent or Bitcoin, are not
  fully distributed, but use centralized services to provide a functional
  ecosystem. The file-sharing part of BitTorrent is distributed, but for 
  torrent search and metadata download users still use trackers. Those
  centralized servers are set up by a third-party and have total authority over
  their behavior. The reason why this set up works seamlessly is that
  there is not one central server, but multiple independent authorities. If a
  tracker starts behaving maliciously then it is noticed and search browsers do
  not return links to the malicious tracker. Similar set up is done in Ghoul.

  Tor anynomizing network \cite{syv04}, which is used worldwide by, for example,
  political dissidents and whistleblowers to protect against government
  surveillance, also relies on central authority. Tor currently uses 9 directory
  authorities
  \footnote{\texttt{https://www.torproject.org/docs/faq#KeyManagement}
  \footnote{\texttt{https://atlas.torproject.org/#search/flag:authority}
  which keep a signed list of active Tor nodes.
  A Tor client contacts all directory authorities to download this list and
  trusts relays that are confirmed by a consensus of directory authorities.
  If an adversary were to shut down directory authorities (through for example a
  DDOS attack), then she would effectively shut down the entire Tor network.
  In contrast, in Ghoul, compromise of the central authority would stop new
  nodes from joining the network.

  Introduction of central authority is necessary for efficient security.
  Gatekeeper servers ensure that distributed keys are truly random, something
  that would be inefficient in a distributed setting. Centralized cetrification
  system allows adding extensions and boost security mechanism which can
  recognize malicious nodes.

  The gatekeeper functionality in Ghoul is only used for node join and doesn't
  require any complex computational power. Even if node join fails or becomes
  congested the network is still usable. Already certfied nodes may still
  operate normally and external nodes may use it for node-search.
